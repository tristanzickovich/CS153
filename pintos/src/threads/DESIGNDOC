            +--------------------+
            |        CS 153      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tristan Zickovich <tzick002@ucr.edu> <861090329>
Thomas Liu <tliu020@ucr.edu> <861073940>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


static struct list sleepingList; -list of sleeping threads in timer.h

int64_t wake_time; - the time we wake. Located in thread.h
struct list_elem sleep_element; - list_elem to put thread into sleepingList



---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Timer_sleep() puts the thread to “sleep” by blocking the thread. It also puts the thread into a list along with the wakeup time. This way, threads will no longer hog up cpu cycles while they’re supposedly doing nothing.
When Timer_inturrupt calls, it unblocks all threads that passed the waking time. Allowing them to be called again.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

We will sort the threads by wake time to minimize the amount of time spent in the interrupt handler.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

A thread attempting to access the critical section of the code gets a lock (if no other thread has a lock at the time). Once locked, no other threads can access that code until the lock is released by the previous thread.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?


We disable interrupts when adding threads to the list (the potential cause of race conditions). Interrupts are disabled before we add the threads to the wait list, and are re-enabled once the thread has been added.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?


The original design makes threads busy wait, meaning it will use cpu cycles even though it isn’t doing anything. The new design will completely skip over waiting threads.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


We will add a struct to keep track of the locked threads,
global values to set and get priority in threads and a comparator to threads that compares priority.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)


Priority donation will occur when a higher priority thread must wait on a low priority thread, the high priority thread will “donate” priority to the low priority thread to allow the low priority thread to finish even if it otherwise wouldn’t.

If we have threads H, M, L with respective priority of 60, 40, 20

Here we have thread H waiting for thread L to finish with its lock.
   H -> [   L   ]               _ -> [   H   ]
                    =>
If we have a medium priority thread in a different lock, it would normally be executed before the low priority thread.

   H -> [   L   ]               H -> [   L   ]
                    =>    
...M -> [   M   ]             ... -> [   M   ]

This would result in the H thread not getting run despite having higher priority. As such when we check priority, we get the priority of all threads waiting, allowing the High priority thread to get executed more quickly.

   H -> [   L(H)]               _ -> [   H   ]
                    =>    
...M -> [   M   ]            ...M -> [   M   ]


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

In the sleeping threads list, they will be sorted by highest priority. This will ensure the highest priority thread wakes up first.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

The current thread is placed on the lock owners list of donors. The threads priority is given to the thread owning the lock (provided its own priority is less). Then the current thread attains the lock and the previous locked thread waits for the new locked thread.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.


Priority donation is removed upon lock release. The current thread’s priority is updated. The thread on the waiting list with highest priority will then be selected and placed on the ready queue. If the current thread’s priority is still greatest, it will be run. Otherwise the processor will take control.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A race condition is created when multiple threads try and change the same priority at the same time. We can disable interrupts so there will only be one thread accessing thread_set_priority(). Changing the priority in a lock can avoid the race, but it will mean thread priority donation will freeze for that thread. This is bad because the locks themselves run on priority donations meaning this can result in threads being unable to correctly donate leaving preventing high priority threads from executing. It can even lead to a deadlock situation where threads try and fail at getting priority from waiting threads.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?


We add priority to threads because not each thread has equal importance. We want threads with high priority to execute sooner than low priority threads. As such, we use a sorted readylist of threads to indicate which threads to run next. However, the readylist wouldn’t matter if threads already running don’t reflect the priority of the readylist. As such, we use priority donation in order to allow threads to finish executing more quickly allowing high priority threads to run, even if they’re in the readylist.

              ADVANCED SCHEDULER
                (If Attempted)
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?

